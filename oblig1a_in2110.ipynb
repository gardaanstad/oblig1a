{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN2110 obligatorisk innlevering 1a\n",
    "**Våren 2024**\n",
    "\n",
    "Det er en god idé å lese gjennom hele oppgavesettet før du setter i gang.\n",
    "Dersom du har spørsmål så kan du:\n",
    "- gå på gruppetime,\n",
    "- spørre på  Discourse \n",
    "- eller sende epost til in2110-hjelp@ifi.uio.no dersom alternativene over av en eller annen grunn ikke passer for spørsmålet ditt.\n",
    "\n",
    "## Oppsett\n",
    "Når du har klonet dette github-repoet som denne notebooken ligger i, har du tilgang til datene og hjelpefilene som ligger i denne mappa. Hvis du ønsker å kopiere denne mappa, \"1a\", over til et annet sted, så skulle det gå bra. Bare pass på at du følger med på om det er oppdateringer her i repoet som gir ut obligen. Når du har aktivert in2110-miljøet med conda, så har du tilgang til pakkene som trengs for å kjøre denne notebooken.\n",
    "\n",
    "## Bakgrunn\n",
    "For denne innleveringen skal vi jobbe med datasettet Norwegian Review Corpus\n",
    "(NoReC) som består av anmeldelser hentet fra en rekke norske nettaviser.\n",
    "NoReC består av over 35.000 dokumenter fordelt på 9 tematiske kategorier. I dataene som er klargjort for oppgaven, er to av kategoriene fjernet for å spare plass. Vi skal kun se på 3 av de gjenstående kategoriene: ‘games’, ‘restaurants’ og ‘literature’. I oppgavene som følger skal vi skal jobbe med å *(i)* pre-prosessere tekstene, *(ii)* representere dem i en vektorrom-modell og så *(iii)* lage en klassifikator for å predikere hvilken kategori en gitt anmeldelse tilhører.\n",
    "\n",
    "## Datagrunnlaget\n",
    "Når vi jobber med klassifikasjon er det viktig at vi setter til side en del av\n",
    "dokumentene slik at vi kan bruke disse til å evaluere klassifikatoren. NoReC er\n",
    "delt i tre deler: ‘train’, ‘dev’ og ‘test’. Det er god praksis å trene med treningssettet\n",
    "(‘train’), evaluere underveis med valideringssettet (‘dev’ for *development*)\n",
    "og spare testsettet (‘test’) helt til slutt. Tekstene i NoReC er sortert på forhånd for å splittes i  ‘train’, ‘dev’ og ‘test’. Informasjonen om hvilken split dokumentet tilhører, ligger i metadata for hvert dokument. Slik dataene er lagret, er det en liste av dict- én for hvert dokument. Under nøkkelen \"text\" ligger teksten i dokumentet, og under nøkkelen \"metadata\" ligger en ny dict der vi kan finne kategorien til dokumentet, og hvilken split det tilhører. \n",
    "\n",
    "\n",
    "## Innleveringsformatet\n",
    "Innleveringen skal helst bestå av én Jupyter notebook med både kode og tilhørende forklaringer. **La det siste du gjør før innlevering være å kjøre hele notebooken før du lagrer siste gang. Den skal kjøre uten å feile, og vise den grafikken og de utskriftene som skal være med.**\n",
    "Vi understreker at innlevering av koden alene ikke er nok for å bestå oppgaven\n",
    "– vi forventer at notebooken også skal inneholde beskrivelser (på norsk eller engelsk)\n",
    "av hva dere har gjort og begrunnelser for valgene dere har tatt underveis. Bruk helst\n",
    "hele setninger, og matematiske formler om nødvendig. La enhver oblig bli en trening i å formidle forskning. Evalueringstallene bør presenteres i tabeller. Det å forklare med egne ord (samt begreper vi har gått gjennom på\n",
    "forelesningene) hva dere har implementert og reflektere over hvorvidt løsningen dere\n",
    "har lagt besvarer oppgaven er en viktig del av læringsprosessen – ta det på alvor! \n",
    "Vi foretrekker som sagt at innleveringen deres kun består av én Jupyter notebook, men hvis\n",
    "dere av tekniske grunner ikke klarer å besvare alle spørsmålene med Jupyter kan dere\n",
    "også levere vanlige Python filer med en PDF-rapport som inneholder grafikken fra visualiseringen, og deres tekst-besvarelser.\n",
    "\n",
    "### Tips for jobbing med notebooks\n",
    "Det er en god idé å teste kode snarest mulig etter at du har lagd en ny funksjon. Lag deg gjerne ei ny celle i notebooken der du skriver ut et eksempel på dine data, og tester koden med eksempeldata som du lager deg. Slik testing er ikke en del av oppgaven, og kan slettes hvis den tar mye plass under kjøring. \n",
    "\n",
    "I prekoden står det `None` flere steder. Her skal din kode inn i stedet. I tillegg skal din kode inn de andre stedene der teksten sier det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from helpers_1a import scatter_plot\n",
    "\n",
    "# NLTK-ressurser vi skal ha tilgjengelig i denne obligen\n",
    "resources = {\"punkt\": \"tokenizers/punkt\"}\n",
    "\n",
    "for name, path in resources.items():\n",
    "    try:\n",
    "        nltk.data.find(path)\n",
    "    except LookupError:\n",
    "        nltk.download(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1 Data og pre-prosessering\n",
    "### a) Data\n",
    "Under er det en funksjon kalt prepare_data(). Denne tar inn en iterator\n",
    "over dokumenter og skal returnere to lister: en liste med dokumenttekstene og\n",
    "en liste med den respektive kategorien for hvert av dokumentene.\n",
    "Skriv ferdig prepare_data(). Husk at vi kun ønsker dokumentene\n",
    "i kategoriene ‘games’, ‘restaurants’ og ‘literature’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(documents, split): # Oppgave 1 a\n",
    "    \"\"\"Tar inn en liste av dokumenter fra norec\n",
    "    og returnerer to lister:\n",
    "\n",
    "    - data   : En liste over dokument-tekstene.\n",
    "    - labels : En liste over hvilken kategori dokumentet tilhører.\n",
    "\n",
    "    Begge listene skal være like lange og for dokumentet i data[i]\n",
    "    skal vi kunne finne kategorien i labels[i].\n",
    "\n",
    "    Hvert element i listen documents er en dict der teksten ligger under nøkkelen \"text\", \n",
    "    og metadata ligger under nøkkelen \"metadata\".\n",
    "\n",
    "    Dataene som sendes til funksjonen tilhører mange forskjellige kategorier (\"category\"). Vi skal bare ha disse tre: 'games','restaurants' og 'literature'.\n",
    "    Parameteret \"split\" skal inneholde en av 'train', 'dev' eller 'test'. Bare dokumenter som har tilsvarende verdi i \"split\", skal returneres.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Din kode her\n",
    "    # Intern funksjon for å sjekke om split og category er riktig\n",
    "    def meets_requirements(document: dict, split: str):\n",
    "        if not document.get(\"metadata\").get(\"split\") == split:\n",
    "            return False\n",
    "        if document.get(\"metadata\").get(\"category\") not in [\"games\", \"restaurants\", \"literature\"]:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    data = [d.get(\"text\") for d in documents \n",
    "            if meets_requirements(d, split)]\n",
    "    \n",
    "    labels = [d.get(\"metadata\").get(\"category\") for d in documents\n",
    "              if meets_requirements(d, split)]\n",
    "    \n",
    "    data = list(data)\n",
    "    labels = list(labels)\n",
    "    \n",
    "    assert len(data) == len(labels)\n",
    "    return data, labels\n",
    "\n",
    "def tokenize(text: str):\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "def nltk_tokenize(text: str): #Oppgave 1 b\n",
    "    \"\"\"Tar inn en streng med tekst og returnerer en liste med tokens.\"\"\"\n",
    "    # Å splitte på mellomrom er fattigmanns tokenisering. Endre til noe bedre!\n",
    "    text = text.lower()\n",
    "    tokenized = word_tokenize(text)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prekode: Her laster vi inn dataene, etter at du har skrevet ferdig prepare_data()\n",
    "datakilde = \"norec_excerpts.json\"\n",
    "with open (datakilde, encoding = \"utf-8\") as rf:\n",
    "    norecdata = json.load(rf)\n",
    "\n",
    "# Treningsdata\n",
    "train_data, train_labels = prepare_data(norecdata, \"train\")\n",
    "\n",
    "# Valideringsdata\n",
    "dev_data, dev_labels = prepare_data(norecdata, \"dev\")\n",
    "\n",
    "# Testdata\n",
    "test_data, test_labels = prepare_data(norecdata, \"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1\n",
    "### b) Pre-prosessering\n",
    "Prekoden over inneholder funksjonen tokenize() som splitter på mellomrom. Vi\n",
    "ønsker en bedre tokenisering av dokumentene.\n",
    "- Tokeniser treningssettet med den originale funksjonen og rapporter hvor mange tokens og hvor mange ordtyper du får.\n",
    "- Endre funksjonen til å bruke en bedre tokenizer, f.eks. word_tokenize\n",
    "i NLTK. Rapporter antall tokens og ordtyper for denne også.\n",
    "- Prøv andre typer pre-prosessering, som f.eks. å gjøre om alle ord\n",
    "til små bokstaver, normalisering av tall, eller normalisering av\n",
    "tokens som betyr det samme (som f.eks. forskjellige typer hermetegn). \n",
    "\n",
    "Rapporter antall tokens og ordtyper for alle .\n",
    "Hvilken tokenisering gir lavest antall ordtyper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:        1829550\n",
      "unique tokens: 186519\n"
     ]
    }
   ],
   "source": [
    "# Oppgave 1 b) din kode:\n",
    "# Skriv koden som sender treningssettet til tokenize()\n",
    "# Og som teller opp antall tokens som returneres, og antall ordtyper (=antall unike tokens) i hele treningssettet.\n",
    "\n",
    "# tokenize train_data med .split()-tokenizer (0.3 sec)\n",
    "def tokenize_data(data: []):\n",
    "    all_tokens = [t for text in train_data for t in tokenize(text)]\n",
    "    unique_tokens = set(all_tokens)\n",
    "    \n",
    "    return len(all_tokens), len(unique_tokens)\n",
    "\n",
    "token_amount, unique_token_amount = tokenize_data(train_data)\n",
    "print(f\"tokens:        {token_amount}\\nunique tokens: {unique_token_amount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens:        2085886\n",
      "unique tokens: 115934\n"
     ]
    }
   ],
   "source": [
    "# tokenize train_data med nltk-tokenizer (8.7 sec)\n",
    "def nltk_tokenize_data(data: []):\n",
    "    all_tokens = [t for text in data for t in nltk_tokenize(text)]\n",
    "    unique_tokens = set(all_tokens)\n",
    "\n",
    "    return len(all_tokens), len(unique_tokens)\n",
    "\n",
    "token_amount, unique_token_amount = nltk_tokenize_data(train_data)\n",
    "print(f\"tokens:        {token_amount}\\nunique tokens: {unique_token_amount}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 1 b) Tekstbesvarelse\n",
    "*Legg resultatene fra de ulike tokeniseringene inn hit, og ditt svar på hvilken tokenisering som gir lavest antall ordtyper*\n",
    "\n",
    "Vanlig .split()-tokenizer ga 1829550 tokens og 186519 ulike ordtyper.\n",
    "\n",
    "nltk sin word_tokenizer ga 2085886 tokens og 115934 ulike ordtyper.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1 c) Statistikk\n",
    "- Beregn antall dokumenter per kategori (‘games’, ‘restaurants’ og\n",
    "‘literature’) i treningssettet.\n",
    "- Diskuter kort fordelingen mellom kategoriene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'games': 1413\n",
      "'restaurants': 428\n",
      "'literature': 2821\n"
     ]
    }
   ],
   "source": [
    "# Din kode her for å beregne antall dokumenter per kategori\n",
    "def documents_per_category(labels, category):\n",
    "    return len([x for x in labels if x == category])\n",
    "\n",
    "amount_of_games_documents = documents_per_category(train_labels, \"games\")\n",
    "amount_of_restaurants_documents = documents_per_category(train_labels, \"restaurants\")\n",
    "amount_of_literature_documents = documents_per_category(train_labels, \"literature\")\n",
    "\n",
    "print(f\"'games': {amount_of_games_documents}\")\n",
    "print(f\"'restaurants': {amount_of_restaurants_documents}\")\n",
    "print(f\"'literature': {amount_of_literature_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 1 c) Tekstbesvarelse\n",
    "*Diskuter kort fordelingen mellom kategoriene:*\n",
    "\n",
    "Det er flest 'literature'-dokumenter (2821), så 'games'-dokumenter (1413), og til slutt 'restaurant'-dokumenter (428)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 2 Dokumentrepresentasjon\n",
    "Vi ønsker å representere dokumentene som vektorer, som vi så kan bruke som\n",
    "input til å trene en klassifikator. Klassifikatoren lar oss predikere hvilken kategori et gitt\n",
    "dokument tilhører. For å gjøre dette skal vi bruke scikit-learn. De klassene og\n",
    "funksjonene dere trenger, er allerede importert i prekoden. Bruk gjerne litt tid\n",
    "på å se på veiledningene på http://scikit-learn.org. I denne seksjonen skal\n",
    "vi jobbe med å lese inn dokumentene og lage vektorrepresentasjoner. Så skal vi\n",
    "jobbe med selve klassifikatoren i neste seksjon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 2 a) Vektorisering\n",
    "For å lage en tall-representasjon av dokumentene, skal vi bruke `CountVectorizer` fra scikit-learn for\n",
    "å lage bag-of-words-representasjoner. Den tar inn en iterator\n",
    "over dokumenter og returnerer en dokumentvektor for hvert dokument. Fordi\n",
    "ordforrådet er så stort – over 500 000 ordtyper for hele NoReC – blir hver enkelt\n",
    "dokumentvektor 500 000-dimensjonale hvis vi bruker alle ordene. Vi kommer til å\n",
    "begrense oss til de 5000 mest frekvente ordene. Dette reduserer både minnebruk\n",
    "og kjøretid.\n",
    "CountVectorizer tar veldig mange argumenter, men dere kan ignorere de\n",
    "fleste av dem; de eneste som er viktige for oss er lowercase, tokenizer og\n",
    "max_features. Vi ønsker å bruke vår egen tokenizer, ikke den innebygde i\n",
    "CountVectorizer, og vi ønsker heller ikke å la den gjøre om til lowercase –\n",
    "vi kan heller gjøre om til små bokstaver i tokenize() om vi skulle ønske det.\n",
    "Bruk argumentet max_features til å begrense ordforrådet. For å kunne ta i bruk\n",
    "CountVectorizer må vi først identifisere ordtypene som skal inngå i ordforrådet / vokabularet til modellen. Det kan vi gjøre med metoden `fit()`. Det er\n",
    "viktig at vi kun bruker trenings-settet for dette. Etter vi har identifisert vokabu-\n",
    "læret kan vi anvende vektorisereren med `transform()`; dette vil altså opprette\n",
    "dokumentvektorene. \n",
    "\n",
    "Endre prekoden under, slik at vi får: \n",
    "- instansiert en CountVectorizer med parametrene som beskrevet over\n",
    "- trent vår vectorizert på våre treningsdata\n",
    "- transformert både train, dev og test med vår trente vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vektorisering\u001b[39;00m\n\u001b[1;32m      2\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# CountVectorizer med våre parametre\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# Tren vectorizer på våre data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m train_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Bruk vectorizer til å transformere våre data\u001b[39;00m\n\u001b[1;32m      5\u001b[0m dev_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Bruk vectorizer på våre data\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "# Vektorisering\n",
    "vectorizer = None # CountVectorizer med våre parametre\n",
    "vectorizer.fit(None) # Tren vectorizer på våre data\n",
    "train_vec = None # Bruk vectorizer til å transformere våre data\n",
    "dev_vec = None # Bruk vectorizer på våre data\n",
    "test_vec  = None # Bruk vectorizer på våre data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 2 b) Visualisering\n",
    "*Hvis du har eksportert notebooken til .py og kjører uten grafisk grensesnitt, vil visualiseringen lagres som en PNG-fil.*\n",
    "\n",
    "Nå har vi vektorisert dokumentene, men vi vet ikke om disse vektor-representasjonene\n",
    "er gode eller ikke. For å få litt mer innsikt skal vi visualisere vektorene i treningssettet. Vi har laget en ferdig funksjon som dere kan bruke:\n",
    "```\n",
    "scatter_plot(vectors, labels)\n",
    "```\n",
    "Hvor `vectors` er de vektoriserte dokumentene og `labels` er listen over kategorien\n",
    "til hvert av dokumentene. Visualiseringen viser en prikk for hvert dokument,\n",
    "med farge avhengig av hvilken kategori det tilhører. Ideelt sett skulle vi sett at\n",
    "hver kategori var en helt separat klynge, men i praksis er det alltid noe overlapp\n",
    "mellom kategorier.\n",
    "\n",
    "Visualiser dokumentvektorene for treningssettet. Beskriv og diskuter hva du ser.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Oppgave 2 b) Visualisering\n",
    "# Din kode for å visualisere treningsdataene ved hjelp av  scatter_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 2 b) Tekstbesvarelse\n",
    "*Beskriv og diskuter hva du ser i plottet.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opppgave 2 c) Vekting\n",
    "For å få bedre representasjoner kan det være lurt å vekte trekkene i ordvektorene,\n",
    "slik at de trekkene som er mer informative gis høyere vekt. Vi skal se på en type\n",
    "vekting kalt *term frequency–inverse document frequency (tf-idf)*. Scikit-learn\n",
    "har en innebygd klasse for tf-idf kalt `TfidfTransformer` som vi skal bruke.\n",
    "Den tar dokumentvektorer som input og gir ut nye vektorer som output. I\n",
    "likhet med CountVectorizer må denne tilpasses treningssettet med fit() eller\n",
    "fit_transform() før vi kan ta den i bruk (fordi vi først må gjøre de nødvendige\n",
    "frekvenstellingene i korpuset).\n",
    "- Lag en tf-idf-vektet representasjon av dokumentene\n",
    "- Visualiser treningsvektorene som er vektet med tf-idf. Ser du\n",
    "noen forskjell mellom vektorene med og uten tf-idf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opppgave 2 c) Vekting, din kode:\n",
    "tfifdf_transformer = None # Instans av TfidfTransformer\n",
    "tfifdf_transformer.fit(None) # Tren instansen på våre data\n",
    "train_vec_tfidf = None # Treningsdata tf-idf-transformert\n",
    "dev_vec_tfidf = None # Dev-data tf-idf-transformert\n",
    "test_vec_tfidf = None # Testdata tf-idf-transformert\n",
    "\n",
    "# Din kode for å visualisere tf-idf-transformerte treningsdata:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 2 c) Tekstbesvarelse\n",
    "*Ser du noen forskjell mellom vektorene med og uten tf-idf?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 3: Klassifisering\n",
    "Vi skal bruke k-NN for å predikere hvilken kategori dokumentene i valideringssettet og testsettet tilhører ved hjelp av `KNeighborsClassifier` fra scikit-learn.\n",
    "Klassifikatoren trenes med fit() på treningsdataene og kan brukes for å predikere med predict() på testdata. For best resultat er det viktig at trenings- og\n",
    "testdataene er pre-prosessert på samme måte. F.eks. vil en klassifikator trent\n",
    "uten tf-idf gi dårlige resultater for dokumentvektorer med tf-idf. \n",
    "#### Hyper-parameter tuning\n",
    "Ved å endre på verdien av k kan man tilpasse klassifikatoren. Avhengig av datasett, preprosessering og vekting vil forskjellige verdier av k kunne gi forskjeller i ytelse. *K* er en hyperparameter i dette maskinlæringsprosjektet, og vi skal øve på å finne beste hyperparameter, ved å prøve en rekke alternativer for å se hva som gir best resultat. Det er her dev-settet kommer inn som et midlertidig testsett mens vi utvikler beste modell. Siden vi definerer \"beste modell\" som den som gjør det best på dev-settet, er det viktig at vi sparer det endelige testsettet til slutt, slik at vi ser hvordan modellen fungerer på data som vi ikke har brukt på noe trinn i utviklingen av modellen.\n",
    "\n",
    "### a) k-NN\n",
    "Lag en instans av KNeighborsClassifier der k = 3. Tren denne på treningsdata, og test på dev-data ved hjelp av accuracy_score\n",
    "\n",
    "### b) Evaluering\n",
    "Et vanlig brukt mål får å evaluere en klassifikator er accuracy. Vi kan beregne\n",
    "dette ved hjelp av funksjonen `accuracy_score()` fra scikit-learn. Den tar to\n",
    "argumenter: en liste med sanne merkelapper og en med predikerte merkelapper.\n",
    "De sanne merkelappene er listen over kategorier for hvert dokument som vi\n",
    "fikk fra NoReC (altså såkalte ‘gull-standard’ merkelapper), mens de predikerte\n",
    "er modellens egne som vi får fra predict(). \n",
    "\n",
    "**Hyper-parameter tuning:** \n",
    "Lag ei sløyfe som trener en klassifikator for forskjellige verdier av k med og uten tf-idf, \n",
    "og beregn accuracy for hver av dem. Du kan f.eks. teste med k fra 1 til 20. \n",
    "- Inkluder en tabell med resultatene i rapporten.\n",
    "- Diskuter resultatene dine. Hvilken kombinasjon av vekting og k-\n",
    "verdi gir best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 3 a) Din koding:\n",
    "\n",
    "# Lag en instans av KNeighborsClassifier der k = 3:\n",
    "knn_clf = None\n",
    "# Tren denne på treningsdata:\n",
    "\n",
    "# Test klassifikatoren ved hjelp av accuracy_score():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oppgave 3 b) Din koding:\n",
    "\"\"\"Lag ei sløyfe som trener en klassifikator for forskjellige verdier av k med og uten tf-\n",
    "idf, og beregn accuracy for hver av dem:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3b Tekstbesvarelse\n",
    "- Inkluder en tabell med resultatene i rapporten.\n",
    "- Diskuter resultatene dine. Hvilken kombinasjon av vekting og k-verdi gir best accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 3 c) Testing\n",
    "Vi har tilpasset parameterene til klassifikatoren vår til valideringssettet og nå\n",
    "ønsker vi å gjøre en siste evaluering på testsettet. For å få mest mulig realistiske\n",
    "og representative resultater er det viktig at vi venter med dette helt til slutt,\n",
    "slik at vi ikke tilpasser klassifikatoren testsettet. Fordi vi vil teste hvor bra\n",
    "klassifikatoren vår kan generalisere til nye data, må vi være nøye på at det\n",
    "reserverte testsettet er nettopp dette – nye data som ikke har påvirket de valgene\n",
    "vi har tatt for klassifikatoren vår.\n",
    "\n",
    "- Tren en klassifikator med samme valg for k-verdi og vekting (tf-idf\n",
    "eller ikke) som den med høyest accuracy i forrige deloppgave.\n",
    "- Test på tilsvarende representasjon av test-settet\n",
    "- Hvordan er ytelsen på testsettet sammenlignet med valideringssettet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Din kode for trening av modell med beste parametre, og teste på test-settet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppgave 3c Tekstbesvarelse\n",
    "*Hvordan er ytelsen på testsettet sammenlignet med valideringssettet?*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
